{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dd_logo.png\" />\n",
    "\n",
    "# Distributed Tracing with Datadog APM\n",
    "\n",
    "Now that we've got the basics for how traces work, it's time to use a real world server. In our case, we'll use `docker-compose` to load up a running instance, and manipulate things from there.\n",
    "\n",
    "Before we get started, be sure to check out the repo that goes along with this. It'll have everything you need.\n",
    "\n",
    "If you're running this notebook locally, you should already be good. Otherwise, you'll want to:\n",
    "\n",
    "```bash\n",
    "$ git clone https://github.com/burningion/dash-apm-workshop\n",
    "$ cd dash-apm-workshop\n",
    "$ jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Becoming Acquainted with the Example Project\n",
    "\n",
    "Before we instrument our example project, let's become familiar with its architecture.\n",
    "\n",
    "Open up a new terminal, and spin up the docker-compose of the repo:\n",
    "\n",
    "```bash\n",
    "$ DD_API_KEY=<YOUR_API_KEY> STEP=1 docker-compose up\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running docker-compose up spins up all the containers for our infrastructure. \n",
    "\n",
    "In this case, we're using docker-compose to spin up two microservices. For now, we've got an API that sits in front of our microservice, and of course, a microservice. \n",
    "\n",
    "The first example is already set up with a basic tracer initialized, so by putting in our key, we can already see traces being sent.\n",
    "\n",
    "Let's try our first `curl` request to the API, and see if we can trace our request across both services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=mankind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Our Traces to See Our Infrastructure\n",
    "\n",
    "Now that we've got a few requests that have been sent, we can take a look at the Datadog APM dashboard, and see what's going on with our service.\n",
    "\n",
    "Looking at the dashboard, it appears our trace which should be a single trace is broken out into two.\n",
    "\n",
    "Our customer facing API is hitting the `thinker` microservice, but the `trace` isn't being propagated across both.\n",
    "\n",
    "This is an example of what we'll encounter when we first get tracing installed on our systems. We now need to instrument them, adding in our links.\n",
    "\n",
    "\n",
    "## Continuing Our Traces Across Services Manually\n",
    "\n",
    "Indeed, if we look at the `thinker.py` file, we can see that even though our `think` function is wrapped in a trace, we're not continuing or checking for any exisisting spans. \n",
    "\n",
    "In order to do that within Flask, we'll need to add a check in our request headers for our `X-Datadog-Trace-Id` and `X-Datadog-Parent-Id`, injecting our `trace_id` and `parent_id` if there are either.\n",
    "\n",
    "Our Python code becomes the following:\n",
    "\n",
    "```python\n",
    "@app.route('/')\n",
    "def think_microservice():\n",
    "    # continue the span from the called service\n",
    "    trace_id = flask_request.headers.get(\"X-Datadog-Trace-Id\")\n",
    "    parent_id = flask_request.headers.get(\"X-Datadog-Parent-Id\")\n",
    "    if trace_id and parent_id:\n",
    "        span = tracer.current_span()\n",
    "        span.trace_id = int(trace_id)\n",
    "        span.parent_id = int(parent_id)\n",
    "\n",
    "    subject = flask_request.args.get('subject')\n",
    "    thoughts = think(subject)\n",
    "    return Response(thoughts, mimetype='application/json')\n",
    "```\n",
    "\n",
    "Notice the `think` function that gets called has a Python decorator. It's wrapping the function call with a span, and inserting the `subject` of the think call into the span's `tag`:\n",
    "\n",
    "\n",
    "```python\n",
    "@tracer.wrap(name='think')\n",
    "def think(subject):\n",
    "    tracer.current_span().set_tag('subject', subject)\n",
    "\n",
    "    sleep(0.5)\n",
    "    return thoughts[subject]\n",
    "```\n",
    "\n",
    "If we want, we can restart our containers now, and see how things look with requests being passed across services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose down\n",
    "!DD_API_KEY=<YOUR_API_KEY> STEP=2 docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Cross Service Spans\n",
    "\n",
    "In order to view our cross service spans, we'll first need to generate some more requests, creating new traces to be sent back to Datadog.\n",
    "\n",
    "Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=war"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try generating an error in our application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/think/?subject=mankind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we switch over to view our traces in Datadog, we see them coming in as a single span, traversing our microservices.\n",
    "\n",
    "But if you looked closely, you'll see that we have a library that can be instrumented by Datadog, but isn't.\n",
    "\n",
    "That's the `requests` library, that's used to send our requests across from one microservice to the other. \n",
    "\n",
    "## Automatic Instrumentation of Libraries\n",
    "\n",
    "If we use Datadog's Python library function `patch`, we can also instrument the `requests` library, and get all the metadata of our request along with the information set.\n",
    "\n",
    "Our original API becomes:\n",
    "\n",
    "```python\n",
    "import blinker as _\n",
    "import requests\n",
    "\n",
    "from flask import Flask, Response\n",
    "from flask import jsonify\n",
    "from flask import request as flask_request\n",
    "\n",
    "from ddtrace import tracer, patch\n",
    "from ddtrace.contrib.flask import TraceMiddleware\n",
    "\n",
    "\n",
    "# Tracer configuration\n",
    "tracer.configure(hostname='agent')\n",
    "# also patch the requests library\n",
    "patch(requests=True)\n",
    "\n",
    "app = Flask('api')\n",
    "traced_app = TraceMiddleware(app, tracer, service='thinker-api')\n",
    "\n",
    "\n",
    "@app.route('/think/')\n",
    "def think_handler():\n",
    "    thoughts = requests.get('http://thinker:5001/', headers={\n",
    "        'x-datadog-trace-id': str(tracer.current_span().trace_id),\n",
    "        'x-datadog-parent-id': str(tracer.current_span().span_id),\n",
    "    }, params={\n",
    "        'subject': flask_request.args.getlist('subject', str),\n",
    "    }).content\n",
    "    return Response(thoughts, mimetype='application/json')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
